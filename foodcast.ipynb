{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c74dac4e",
   "metadata": {},
   "source": [
    "# Foodcast - food forecasting\n",
    "In this notebook, we propose to explore and understand the different building blocks of a weekly sales forecasting problem. The introduction of [MLflow](https://mlflow.org/) will be done in a second time.\n",
    "\n",
    "The dataset is [this one](https://www.kaggle.com/henslersoftware/19560-indian-takeaway-orders) and is located in the `data` directory of the project. The `data/raw` directory contains the data as is.\n",
    "\n",
    "The scenario is as follows: a restaurant chain has several restaurants in a given city. Each restaurant records its total sales. The chain wants to be able to predict its sales volume from one week to the next, for all locations.\n",
    "\n",
    "The idea is to get into production conditions, with a weekly prediction rhythm. Each week, a processing and forecasting pipeline must be activated. To emulate this kind of environment, we split the data into weekly batches in `data/batches` using the `reformatting.py` script. For simplicity, the weeks are identified with an integer\n",
    "\n",
    "<img src=\"https://mlflow-training.s3.eu-west-3.amazonaws.com/data.png\" style=\"width: 400px;\"/>\n",
    "\n",
    "In this notebook, we discuss the following pipeline steps:\n",
    "* [Importing libraries](#part0)\n",
    "* [Loading and cleaning data](#part1)\n",
    "* [Feature engineering on the training set (offline)](#part2)\n",
    "* [Training a predictive model](#part3)\n",
    "* [Feature engineering on the prediction game (online)](#part4)\n",
    "* [Prediction and visualization](#part5)\n",
    "* [Modeling uncertainties](#part6)\n",
    "\n",
    "**Note:** all elementary functions that implement these steps are **already coded**. In this notebook, it is just a matter of getting familiar with them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878d131f",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641a28bf",
   "metadata": {},
   "source": [
    "Here, we get the project code from a distant cloud storage and install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c0baff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://mlflow-training.s3.eu-west-3.amazonaws.com/requirements.txt\n",
    "!wget https://mlflow-training.s3.eu-west-3.amazonaws.com/mlflow_training.zip\n",
    "!unzip -qq /content/mlflow_training.zip\n",
    "!pip install -r requirements.txt --quiet\n",
    "!rm -rf mlflow_training.zip requirements.txt sample_data __MACOSX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c7c2f9",
   "metadata": {},
   "source": [
    "### Now let's restart the kernel so that the installed librairies get loaded !\n",
    "To do so, click on Execution --> Restart the execution environment "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7399582",
   "metadata": {},
   "source": [
    "# Librairies imports\n",
    "\n",
    "<a class='anchor' id='part0'></a>\n",
    "\n",
    "The project's structure is as follows :\n",
    "\n",
    "<img src=\"https://mlflow-training.s3.eu-west-3.amazonaws.com/tree.png\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80db58d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/mlflow_training/')\n",
    "import yaml\n",
    "import logging\n",
    "import logging.config\n",
    "import pandas as pd\n",
    "pd.set_option('display.min_rows', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('max_colwidth', 400)\n",
    "from foodcast.domain.transform import etl\n",
    "from foodcast.domain.feature_engineering import features_offline, features_online\n",
    "from foodcast.domain.forecast import span_future, cross_validate, plotly_predictions\n",
    "from foodcast.domain.multi_model import MultiModel\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import foodcast.settings as settings\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "with open(settings.LOGGING_CONFIGURATION_FILE, 'r') as f:\n",
    "    logging.config.dictConfig(yaml.safe_load(f.read()))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b7202f",
   "metadata": {},
   "source": [
    "# Data loading and cleaning\n",
    "\n",
    "<a class='anchor' id='part1'></a>\n",
    "\n",
    "In this section, we'll focus on data preprocessing.\n",
    "\n",
    "### Elementary functions\n",
    "\n",
    "The following pre-processing takes place in four steps, each encoded in an elementary function:\n",
    "* `extract`: loads the data from a restaurant in a user-defined time interval\n",
    "* `clean`: cleans the corresponding dataset:\n",
    "    * homogenization of column names\n",
    "    * type corrections\n",
    "    * aggregation of the amount at the transaction level\n",
    "    * deletion of useless columns\n",
    "    * chronological sorting\n",
    "*`merge`: merges the data from each restaurant into a single dataframe representing the restaurant chain\n",
    "* `resample`: resamples the dataset at the hour level\n",
    "\n",
    "\n",
    "### Exercises\n",
    "\n",
    "These four functions are encapsulated in a single master function, called `etl`, which is the subject of the next exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385d557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "etl??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64227dcc",
   "metadata": {},
   "source": [
    "**Exercise :** extract a fully pre-processed dataset for weeks 197 to 200.\n",
    "\n",
    "**Hint :** the name of the directory where the data is located is stored in `settings.DATA_DIR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b880921",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00607551",
   "metadata": {},
   "source": [
    "**Exercise :** plot the revenue against time with [plotly](https://plotly.com/python/line-charts/#line-plot-with-goscatter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a77a229",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "pass\n",
    "fig.update_layout(\n",
    "    title='Cash-in',\n",
    "    xaxis_title='date',\n",
    "    yaxis_title='dollars',\n",
    "    font=dict(\n",
    "        family='Computer Modern',\n",
    "        size=18,\n",
    "        color='#7f7f7f'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a15f91",
   "metadata": {},
   "source": [
    "# Feature engineering on the training set (offline)\n",
    "\n",
    "<a class='anchor' id='part2'></a>\n",
    "\n",
    "In this section, we focus on the feature engineering and the creation of the training set.\n",
    "\n",
    "### Elementary functions\n",
    "The following feature engineering is made in 3 steps, each one being already coded in those functions:\n",
    "* `dummy_day` : encodes the day in the week into 6 binary features.\n",
    "* `hour_cos_sin` : encodes the hour of the day into 2 continous features.\n",
    "* `lag_offline` : Retrieves the revenue of exactly one week ago.\n",
    "\n",
    "Implementation wise, `lag_offline` is just a `shift` of the target variable in the training set.\n",
    "\n",
    "### Exercises\n",
    "\n",
    "These four functions are encapsulated in a single master function, called `features_offline`, which is the subject of the following exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1207d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_offline??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f07e474",
   "metadata": {},
   "source": [
    "**Exercise :** Perform the feature engineering on the training set previously loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73a6558",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c5a712",
   "metadata": {},
   "source": [
    "**Exercise :** check by hand on one or two lines the validity of the variable `lag_1W` just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df04301",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d6a759",
   "metadata": {},
   "source": [
    "### Features / target split\n",
    "\n",
    "We now split the dataset into feature variables and target variable, making sure to keep the date information as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9deed79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to achieve exercise\n",
    "\n",
    "# x_train = df.drop(columns=['cash_in'])\n",
    "# y_train = df[['order_date', 'cash_in']]\n",
    "# x_train = x_train.set_index('order_date')\n",
    "# y_train = y_train.set_index('order_date')['cash_in']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eceb9b1",
   "metadata": {},
   "source": [
    "# Training of a predictive model\n",
    "\n",
    "<a class='anchor' id='part3'></a>\n",
    "\n",
    "In this section, we focus on the training of a predictive model and its validation.\n",
    "\n",
    "### A first basic model\n",
    "To begin with, we introduce a random forest model with 10 trees. \n",
    "\n",
    "**Exercise :** create a `RandomForestRegressor` made of 10 trees, with a fixed random seed (of your choice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63246502",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9095c3c6",
   "metadata": {},
   "source": [
    "### Temporal cross-validation on the training set\n",
    "\n",
    "Temporal cross-validation is natural for a forecasting problem. It is in fact natural for any model life cycle subject to data drift.\n",
    "\n",
    "<img src=\"https://mlflow-training.s3.eu-west-3.amazonaws.com/timeseriessplit.png\" style=\"width: 300px;\"/>\n",
    "\n",
    "It's the `cross_validate` function which implements it, based on [TimeSeriesSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html) from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563dd84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b688c4e1",
   "metadata": {},
   "source": [
    "**Exercise :** Validate the model on the training set 3 times (3 folds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979c0b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "maes, preds = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1250c88d",
   "metadata": {},
   "source": [
    "**Question :** In what unit is the MAE expressed? Given the consumption patterns, is this really a relevant performance indicator?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e94d08",
   "metadata": {},
   "source": [
    "### Plot predictions\n",
    "\n",
    "We can plot the predictions with the `plotly_predictions` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d5fd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_predictions??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d748de1",
   "metadata": {},
   "source": [
    "**Exercise :** Plot predictions obtained with cross-validation, comparing to real targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5134e35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fef76e",
   "metadata": {},
   "source": [
    "### Training on whole data set\n",
    "\n",
    "Is is the `fit` method of `RandomForestRegressor` needed here.\n",
    "\n",
    "**Exercise :** train the model on the whole training set.\n",
    "\n",
    "**Hint :** We can use the `x_train` and `y_train` previously obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa37dec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98c26e6",
   "metadata": {},
   "source": [
    "# Feature engineering on the prediction data (online)\n",
    "\n",
    "<a class='anchor' id='part4'></a>\n",
    "\n",
    "In this section, we'll focus on the creation of the prediction dataset and its feature engineering.\n",
    "\n",
    "### Elementary functions\n",
    "The feature engineering that follows takes place in four steps, each encoded in an elementary function:\n",
    "* `span_future`: generates the prediction dates in the future.\n",
    "* `dummy_day`: encodes the day of the week into 6 binary variables.\n",
    "* `hour_cos_sin` : encodes the time of day in 2 continuous variables.\n",
    "* `lag_online` : retrieves the revenue of a week in the past.\n",
    "\n",
    "### Why lag offline and lag online?\n",
    "\n",
    "Compared to the training set, it is more difficult to compute a lag of revenue on the prediction set because the latter is by definition in the future, and contains no past information.\n",
    "\n",
    "Two methods are possible:\n",
    "\n",
    "* **the expensive RAM method:** this involves concatenating `train` and `future` and performing a `shift`. If the `train` is large, it takes up a lot of memory space while only a small amount of information is of interest.\n",
    "* **the recommended method:** it consists in loading only the observations of the past week, `past`, concatenate with `future`, and perform a `shift`. This uses very little memory (only one week of data).\n",
    "\n",
    "### Exercises\n",
    "\n",
    "These four functions are encapsulated in the functions `span_future` and `features_online`, which are the subject of the next exercises.\n",
    "\n",
    "First, we generate a `past` set that corresponds to the week just before the prediction week.\n",
    "\n",
    "**Exercise:** create a cleaned `past` dataset describing week 200.\n",
    "\n",
    "**Hint:** we can reuse the `etl` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8077e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "past = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0c1048",
   "metadata": {},
   "source": [
    "Then, we need to generate the prediction data, it is the `span_future` function that will cover it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbffba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "span_future??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7d0165",
   "metadata": {},
   "source": [
    "**Exercise :** generate a dataframe of dates to predict in the future (compared to the training data).\n",
    "\n",
    "**Hint :** we can use `past['order_date'].max()` as a starting point to generate our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1267d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "future = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038044f1",
   "metadata": {},
   "source": [
    "All the steps of online feature engineering are gathered in the `features_online` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb34979",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_online??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab1d92d",
   "metadata": {},
   "source": [
    "**Exercise :** create a future prediction game, using the recommended lag online method (see above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e390e1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "future = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7e1b15",
   "metadata": {},
   "source": [
    "**Exercise :** check by hand on one or two lines the validity of the created variable.\n",
    "\n",
    "**Hint :** we can, for example, look in detail at the variables calculated on November 5, 2018 at 6pm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6eff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ca9115",
   "metadata": {},
   "source": [
    "We keep the date information on the index of the prediction data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e561580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to achieve exercise\n",
    "\n",
    "# future = future.set_index('order_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d75617d",
   "metadata": {},
   "source": [
    "# Prediction and visualization\n",
    "\n",
    "<a class='anchor' id='part5'></a>\n",
    "\n",
    "In this section, we focus on predicting the revenue in the future of the training game.\n",
    "\n",
    "### Revenue prediction\n",
    "\n",
    "It is the `predict` method of `RandomForestRegressor` that comes into play."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9914198f",
   "metadata": {},
   "source": [
    "**Exercise :** predict the revenue on the prediction dataset. \n",
    "\n",
    "**Indice :** we'll gather the predictions into a `DataFrame` with the same index as `future` and only one column called `y_pred_simple`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cc6039",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cace4d8a",
   "metadata": {},
   "source": [
    "### Predictions plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5694ce",
   "metadata": {},
   "source": [
    "**Exercise :** plot the predictions with the `plotly_predictions` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1024e11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695c21e5",
   "metadata": {},
   "source": [
    "# Modeling uncertainties (Optional)\n",
    "\n",
    "<a class='anchor' id='part6'></a>\n",
    "\n",
    "n this section, we propose to add uncertainty to our predictions. A simple way to obtain uncertainty in the results is to perturb both the dataset and the model, as shown below.\n",
    "\n",
    "<img src=\"https://mlflow-training.s3.eu-west-3.amazonaws.com/multimodel.png\" style=\"width: 500px;\"/>\n",
    "\n",
    "It is the `MultiModel` class that implements this schema: \n",
    "* bootstrapping on the data\n",
    "* Variation of the random seed of the model (if it exists). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423b7785",
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiModel?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817d127e",
   "metadata": {},
   "source": [
    "**Exercise :** Implement a `MultiModel` made of 10 `simple_model` replicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5446df",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18837f85",
   "metadata": {},
   "source": [
    "### Temporal cross-validation on the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5d670d",
   "metadata": {},
   "source": [
    "**Exercise:** validate the model on the training set with three repetitions (folds).\n",
    "\n",
    "**Hint:** the syntax is identical to that used for `simple_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a033797",
   "metadata": {},
   "outputs": [],
   "source": [
    "maes, preds = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf1b81d",
   "metadata": {},
   "source": [
    "**Question:** what is the mean and standard deviation of the MAEs on each repeat of the cross-validation?\n",
    "\n",
    "**Hint:** `axis=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1177c26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cb3614",
   "metadata": {},
   "source": [
    "### Plot of predictions\n",
    "\n",
    "We can plot the predictions obtained via the `plotly_predictions` function. This function handles the predictions of a multi-model well. In particular, it does not plot a prediction curve but a *range* of predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f244ba4",
   "metadata": {},
   "source": [
    "**Exercise:** plot the predictions obtained by cross-validation against the expected truth.\n",
    "\n",
    "**Hint:** the syntax is identical to the one used for `simple_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a76b46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61223054",
   "metadata": {},
   "source": [
    "### Training on the whole dataset\n",
    "\n",
    "It is the `fit` method from `MultiModel` at play here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49011c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiModel.fit??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beca794c",
   "metadata": {},
   "source": [
    "**Exercise:** train the model on the whole training set.\n",
    "\n",
    "**Hint:** we will use the `x_train` and `y_train` dataframes obtained previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b687f530",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566c28a5",
   "metadata": {},
   "source": [
    "### Sales prediction\n",
    "\n",
    "This is the `predict` method of `MultiModel` that comes into play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac05ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiModel.predict??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60479cd5",
   "metadata": {},
   "source": [
    "**Exercise:** predict the revenue on the prediction set.\n",
    "\n",
    "**Hint:** Be aware of the non-standard API of the `predict` method. Indeed, the `predict` method contains an additional argument, the `context`. This specificity is necessary to be compatible with [MLflow](https://mlflow.org/), but will become invisible afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f4fa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b44abe9",
   "metadata": {},
   "source": [
    "### Visualization of predictions with uncertainty\n",
    "\n",
    "The predictions obtained can be plotted using the `plotly_predictions` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ee902b",
   "metadata": {},
   "source": [
    "**Exercise:** plot the sales forecast on the prediction set. \n",
    "\n",
    "**Hint:** the syntax is identical to that used for `simple_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcf3657",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67dbb0a",
   "metadata": {},
   "source": [
    "# Congrats !\n",
    "\n",
    "You know master the food forecasting use case which is fully compatible with Mlflow as we'll see in the next lab. \n",
    "\n",
    "### To go further\n",
    "\n",
    "In the following lab, we'll see different mlflow functionnalities :\n",
    "* tracking and reproductibility\n",
    "* models packaging\n",
    "* Visualization in the UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c990168",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "foodcast",
   "language": "python",
   "name": "foodcast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
