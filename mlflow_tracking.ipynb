{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b186a1b",
   "metadata": {},
   "source": [
    "# MLflow tracking\n",
    "\n",
    "In this notebook, we propose to implement the processing chain of the *food forecasting* problem in interaction with the [tracking](https://www.mlflow.org/docs/latest/tracking.html) and [flavours](https://www.mlflow.org/docs/latest/models.html#model-customization) APIs of [MLflow](https://mlflow.org/).\n",
    "\n",
    "<img src=\"/mlflow_training/images/mlflow_tracking.jpg\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cfd75b",
   "metadata": {},
   "source": [
    "In the following, we will compare two ways of working:\n",
    "* [MLflow tracking: tutorial](#part1)\n",
    "    * [Generate logs](#spart11)\n",
    "    * [Organize logs in runs](#spart12)\n",
    "    * [Organizing runs into experiments](#spart13)\n",
    "* [Foodcast processing chain with MLflow](#part2)\n",
    "    * [Loading](#spart21)\n",
    "    * [Offline feature engineering](#spart22)\n",
    "    * [Validating](#spart23)\n",
    "    * [Training](#spart24)\n",
    "    * [Online feature engineering](#spart25)\n",
    "    * [Predicting](#spart26)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d094f2b",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be7e161",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://storage.googleapis.com/mlflow-formation/requirements.txt\n",
    "!wget https://storage.googleapis.com/mlflow-formation/mlflow_training.zip\n",
    "!unzip -qq /content/mlflow_training.zip\n",
    "!pip install -r requirements.txt --quiet\n",
    "!rm -rf mlflow_training.zip requirements.txt sample_data __MACOSX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786b3b51",
   "metadata": {},
   "source": [
    "### Now let's restart the kernel so that the installed librairies get loaded !\n",
    "To do so, click on Execution --> Restart the execution environment "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cd6cf2",
   "metadata": {},
   "source": [
    "___\n",
    "# MLflow tracking : tutorial\n",
    "\n",
    "<a class='anchor' id='part1'></a>\n",
    "\n",
    "In this section, we will discover the basics of [MLflow tracking](https://www.mlflow.org/docs/latest/tracking.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4926eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/content/mlflow_training/')\n",
    "import yaml\n",
    "import logging\n",
    "import logging.config\n",
    "from foodcast.domain.transform import etl\n",
    "from foodcast.domain.multi_model import MultiModel\n",
    "from foodcast.application.mlflow_utils import mlflow_log_pandas, mlflow_log_plotly\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import foodcast.settings as settings\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.pyfunc\n",
    "\n",
    "with open(settings.LOGGING_CONFIGURATION_FILE, 'r') as f:\n",
    "    logging.config.dictConfig(yaml.safe_load(f.read()))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1375228f",
   "metadata": {},
   "source": [
    "The following section maps the mlflow port coming from google colab into a publicly accessible url. <br>\n",
    "It will prompt a login page and you can create an account either with real info or fake ones ;)<br>\n",
    "You can then copy the auth token in the NGROK_AUTH_TOKEN variable below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be614f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyngrok import ngrok\n",
    "\n",
    "get_ipython().system_raw(\"mlflow ui --port 5000 &\")\n",
    "\n",
    "ngrok.kill()\n",
    "\n",
    "NGROK_AUTH_TOKEN = \"\"\n",
    "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
    "\n",
    "ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n",
    "print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3eaee4",
   "metadata": {},
   "source": [
    "## Generate logs\n",
    "\n",
    "<a class='anchor' id='spart11'></a>\n",
    "\n",
    "The general idea is to save information in files. This saving process is called logging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9de57f4",
   "metadata": {},
   "source": [
    "### Logging parameters\n",
    "\n",
    "The simplest information to log is the parameter. A parameter is a key-value pair: the key is a name (a string), and the value is a basic python object (`float`, `string` etc.).\n",
    "\n",
    "**Exercise:** log a `age` parameter, containing your age (in years).\n",
    "\n",
    "**Hint:** we will use the method [mlflow.log_param](https://www.mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_param)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59541621",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d497a3a",
   "metadata": {},
   "source": [
    "**Question:** A new directory has just been created: where? what is it called? where is the information logged?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744f7770",
   "metadata": {},
   "source": [
    "### Navigate the graphical interface\n",
    "\n",
    "<a class='anchor' id='ui'></a>\n",
    "\n",
    "Throughout the following, [MLflow](https://mlflow.org/) runs will be viewable via a built-in GUI.\n",
    "\n",
    "This GUI is simply a utility that reads the `mlruns` directory created by [MLflow](https://mlflow.org/).\n",
    "\n",
    "**Exercise:** find the logged information by navigating the [MLflow](https://mlflow.org/) GUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d8368f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow the steps above to achieve this exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d58db67",
   "metadata": {},
   "source": [
    "**Exercise:** log two parameters in one line of code: `age` (your age) and `neighbor_age` (the age of your left neighbor).\n",
    "\n",
    "**Hint:** we will use the method [mlflow.log_params](https://www.mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_params)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df88d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac8d676",
   "metadata": {},
   "source": [
    "### Logging a standard model\n",
    "\n",
    "Beyond parameters, [MLflow](https://mlflow.org/) provides a convention for storing predictive models.\n",
    "\n",
    "**Exercise:** log a `RandomForestRegressor` of any kind into a directory called `my_random_forest`.\n",
    "\n",
    "**Hint: **We can base this on [mlflow.sklearn.log_model](https://www.mlflow.org/docs/latest/python_api/mlflow.sklearn.html#mlflow.sklearn.log_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6d51b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192eb09c",
   "metadata": {},
   "source": [
    "**Question :** What is a model in the [MLflow](https://mlflow.org/) convention?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0582565a",
   "metadata": {},
   "source": [
    "### Logging a custom model\n",
    "\n",
    "If you want to think outside the box and log a home-made model, it must inherit from the `PythonModel` class of [MLflow](https://mlflow.org/) (this is the case for example with our `MultiModel`). On the other hand, to log this model (and later deploy it), we need to provide additional information, namely:\n",
    "* the code which allows to know the API of the model and to deserialize it\n",
    "* the model's dependencies, in the form of a virtual deployment environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25c14817",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mlflow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3bd7a3ff8bd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m mlflow.pyfunc.log_model(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mpython_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMultiModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0martifact_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'my_multi_model'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcode_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'..'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'foodcast'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'domain'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'multi_model.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     conda_env={\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mlflow' is not defined"
     ]
    }
   ],
   "source": [
    "mlflow.pyfunc.log_model(\n",
    "    python_model=MultiModel(RandomForestRegressor()),\n",
    "    artifact_path='my_multi_model',\n",
    "    code_path=[os.path.join('..', 'foodcast', 'domain', 'multi_model.py')],\n",
    "    conda_env={\n",
    "        'channels': ['defaults', 'conda-forge'],\n",
    "        'dependencies': [\n",
    "            'mlflow=1.8.0',\n",
    "            'numpy=1.17.4',\n",
    "            'python=3.7.6',\n",
    "            'scikit-learn=0.21.3',\n",
    "            'cloudpickle==1.3.0'\n",
    "        ],\n",
    "        'name': 'multi-model-env'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a9d6b5",
   "metadata": {},
   "source": [
    "**Question :** What is the difference with the previous example in the `mlruns` repository ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f943a2",
   "metadata": {},
   "source": [
    "### Logging files\n",
    "\n",
    "Finally, for everything else, [MLflow](https://mlflow.org/) allows to log files. As an illustration, we use a dataframe, which is neither a parameter nor a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140ef559",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = etl(settings.DATA_DIR, 199, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40b71db",
   "metadata": {},
   "source": [
    "Since [MLflow](https://mlflow.org/) doesn't specifically provide a `log` method for dataframes, you have to save it to a file first and then log the file.\n",
    "\n",
    "**Exercise:** save `data` to a `data.csv` file.\n",
    "\n",
    "**Hint:** we will not save the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d87bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad44c78",
   "metadata": {},
   "source": [
    "**Exercise:** log the file `data.csv` in a directory `data`.\n",
    "\n",
    "**Hint:** we will use the method [mlflow.log_artifact](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_artifact)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aac01ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59625282",
   "metadata": {},
   "source": [
    "**Exercise:** delete the `data.csv` file that is floating around in your `notebooks` directory.\n",
    "\n",
    "**Hint:** you can run a terminal command directly in a jupyter cell, prefixing it with a `!`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fae202",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e71b46e",
   "metadata": {},
   "source": [
    "**Question :** Is the logged file `data.csv` still in `mlruns` ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430a2b25",
   "metadata": {},
   "source": [
    "###  Factorization\n",
    "\n",
    "A pattern will become recurrent with [MLflow](https://mlflow.org/): \n",
    "* save data locally\n",
    "* log local data in a run, via `log_artifact`.\n",
    "\n",
    "The disadvantage is that this pollutes the working directory with artifacts unnecessarily. To overcome these problems, you can use the `mlflow_utils` module (home-made).\n",
    "\n",
    "The functions `mlflow_log_pandas` and `mlflow_log_plotly` have the same arguments as `mlflow.log_artifact`, but do not pollute the current directory. Instead, the intermediate data (before being logged) is stored in your `/tmp` directory, which is emptied every time you restart your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c82b64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_log_pandas??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407694e7",
   "metadata": {},
   "source": [
    "**Exercise :** Log the dataframe `data` in `artifacts/data/data.csv` using `mlflow_log_pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc5552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e39e4dd",
   "metadata": {},
   "source": [
    "## Organize logs into runs\n",
    "\n",
    "<a class='anchor' id='spart12'></a>\n",
    "\n",
    "For now, all of our previous operations have been logged in the same place. If we rerun the previous cells, all the information will be overwritten. This is because we have been working in a single run until now.\n",
    "\n",
    "Runs are the basic structure of [MLflow tracking](https://www.mlflow.org/docs/latest/tracking.html), and allow to separate the information in different directories.\n",
    "\n",
    "### Encapsulate the logs\n",
    "In order to get a real history of the actions, we have to encapsulate the logs in runs.\n",
    "\n",
    "First of all, the current run must be terminated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b6ecb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6e6a03",
   "metadata": {},
   "source": [
    "Then, we can use the runs as ContextManager, with the `with` keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2212d380",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    mlflow_log_pandas(data, 'data', 'data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48fa189",
   "metadata": {},
   "source": [
    "**Exercise :** Launch the previous cell twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b425416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Come on, this is an easy one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4490df89",
   "metadata": {},
   "source": [
    "**Question:** While browsing the GUI, what do you notice about the contents of the `mlruns` directory?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee91e248",
   "metadata": {},
   "source": [
    "### Examining a run\n",
    "By combining `with` with `as`, we can save the run in a `my_run` variable. We can even give it a `run_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef9827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name='my_run_name') as my_run:\n",
    "    mlflow_log_pandas(data, 'data', 'data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6ac3d",
   "metadata": {},
   "source": [
    "**Exercise:** find the id of the previous run without using the graphical interface.\n",
    "\n",
    "**Hint:** we can use the [run info](https://www.mlflow.org/docs/latest/python_api/mlflow.entities.html#mlflow.entities.Run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9f34f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b725f95",
   "metadata": {},
   "source": [
    "**Hint:** find the complete path where the run saves the artifacts without using the GUI.\n",
    "\n",
    "**Hint:** we can use the [run info](https://www.mlflow.org/docs/latest/python_api/mlflow.entities.html#mlflow.entities.Run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703d4a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d31e2db",
   "metadata": {},
   "source": [
    "**Exercise:** find the name of the run, without using the graphical interface.\n",
    "\n",
    "**Hint:** we can use the [run tags](https://www.mlflow.org/docs/latest/python_api/mlflow.entities.html#mlflow.entities.Run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da197bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf7d3e4",
   "metadata": {},
   "source": [
    "## Organizing runs into experiments\n",
    "\n",
    "<a class='anchor' id='spart13'></a>\n",
    "\n",
    "Rather than putting all the runs in one place, we can arrange them in specific directories, called experiments. The default experiment is called `Default` in the GUI, and corresponds to the subdirectory `0` in `mlruns`.\n",
    "\n",
    "**Tip:** You can think of experiments as *features* branches in git: as soon as you want to develop a new feature, you create a corresponding experiment, so that you don't mix runs that have nothing to do with each other.\n",
    "\n",
    "### Create an experiment\n",
    "\n",
    "You can create an experiment in python or in command line.\n",
    "\n",
    "**Exercise:** create an experiment called `my_experiment`.\n",
    "\n",
    "**Hint:** the function [set_experiment](https://www.mlflow.org/docs/latest/python_api/mlflow.html#mlflow.set_experiment) allows you to choose a default experiment if it exists, and to create it if it does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aa0d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c24bd3",
   "metadata": {},
   "source": [
    "### Choosing an experiment\n",
    "\n",
    "The choice of experiment can be made at run time via the `experiment_id` argument to `start_run`. However, now that `my_experiment` is the default experiment, there is no need to even bother!\n",
    "\n",
    "**Exercise:** take the last run you did and run it in the `my_experiment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05104070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Come on, the code is elsewhere"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01151f17",
   "metadata": {},
   "source": [
    "**Question :** What happened in the UI ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe2c1c7",
   "metadata": {},
   "source": [
    "### Delete an experiment\n",
    "\n",
    "The safest and most permanent way to delete an experiment is to delete the corresponding directory in `mlruns` and the contents of `mlruns/.trash`.\n",
    "\n",
    "**Hint:** delete the experiment `my_experiment`.\n",
    "\n",
    "**Hint**: You can run a unix command in a jupyter cell with the prefix `!`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a150a186",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afb446c",
   "metadata": {},
   "source": [
    "**Question :** Is the experience still appearing in the UI ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540f5fb8",
   "metadata": {},
   "source": [
    "___\n",
    "# foodcast processing chain with MLflow\n",
    "\n",
    "<a class='anchor' id='part2'></a>\n",
    "\n",
    "As a reminder, the scenario is a weekly sales forecast. The training set is a sliding window in one-week steps, and the prediction set is always the following week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c18e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/content/mlflow_training/')\n",
    "import yaml\n",
    "import logging\n",
    "import logging.config\n",
    "from foodcast.domain.transform import etl\n",
    "from foodcast.domain.feature_engineering import features_offline, features_online\n",
    "from foodcast.domain.forecast import span_future, cross_validate, plotly_predictions\n",
    "from foodcast.domain.multi_model import MultiModel\n",
    "from foodcast.application.mlflow_utils import mlflow_log_pandas, mlflow_log_plotly\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import foodcast.settings as settings\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.pyfunc\n",
    "\n",
    "with open(settings.LOGGING_CONFIGURATION_FILE, 'r') as f:\n",
    "    logging.config.dictConfig(yaml.safe_load(f.read()))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b523c3",
   "metadata": {},
   "source": [
    "If this notebook was \"put into production\", it would have to be restarted each week by updating the following parameters:\n",
    "* `start_week`: the number of the first week of training,\n",
    "* `end_week`: the number of the last week of training,\n",
    "* `next_week`: the number of the prediction week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03db8d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_week = 180\n",
    "end_week = 200\n",
    "next_week = 201"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612a9d9b",
   "metadata": {},
   "source": [
    "## Creating and selecting a dedicated experience\n",
    "Before starting, we propose to create a dedicated foodcast experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a61e6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment('foodcast')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f272f5",
   "metadata": {},
   "source": [
    "## Tip\n",
    "\n",
    "In the following, make sure that the first lines of code after the `with mlflow.start_run()` are the ones that log the run parameters. In case of a crash, you will have logged the information and can investigate more easily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c2edd1",
   "metadata": {},
   "source": [
    "## Loading\n",
    "\n",
    "<a class='anchor' id='spart21'></a>\n",
    "\n",
    "Loads and cleans up the training data on the previously defined sliding window. The data is the sales history of the two restaurants under consideration over the sliding training window defined at the beginning of this notebook.\n",
    "\n",
    "**Exercise:** create a run [MLflow](https://mlflow.org/) that:\n",
    "* is called `load`\n",
    "* log the `start_week` and `end_week` parameters\n",
    "* load and clean up the `data` input data via the `etl` function\n",
    "* log `data` in `data/data.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9ce9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc2000f",
   "metadata": {},
   "source": [
    "## Offline feature engineering\n",
    "\n",
    "<a class='anchor' id='spart22'></a>\n",
    "\n",
    "Feature engineering and train/test separation.\n",
    "\n",
    "**Exercise:** create a run [MLflow](https://mlflow.org/) that:\n",
    "* is called `features`\n",
    "* log the parameters `start_week` and `end_week`.\n",
    "* performs feature engineering via the `features_offline` function\n",
    "* perform the variable/target separation `x_train` / `y_train`\n",
    "* log the dataframes obtained in `training_set/x_train.csv` and `training_set/y_train.csv`.\n",
    "* pass the date of the events in index for `x_train` and `y_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2829e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name='features'):\n",
    "    # TODO: log parameters\n",
    "    train = None\n",
    "    x_train, y_train = None, None\n",
    "    # TODO: log x_train\n",
    "    # TODO: log y_train\n",
    "    # x_train = x_train.set_index('order_date')\n",
    "    # y_train = y_train.set_index('order_date')['cash_in']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cddf80",
   "metadata": {},
   "source": [
    "## Validating\n",
    "\n",
    "<a class='anchor' id='spart23'></a>\n",
    "\n",
    "Model instantiation and chronological cross validation.\n",
    "\n",
    "**Exercise:** create a run [MLflow](https://mlflow.org/) that:\n",
    "* is called `validate`\n",
    "* log the parameters `start_week`, `end_week`, `n_fold`, `n_estimators`, `n_models`.\n",
    "* instantiate a `MultiModel` random forest (`n_estimators=10`, `n_models=10`)\n",
    "* validate the model by 10-fold cross-validation via the `cross_validate` function\n",
    "* log the predictions obtained in `cross_validation/predictions.csv` (don't forget to `reset_index()`)\n",
    "* log the figure obtained via `plotly_predictions` in `plots/validation.html`\n",
    "* log the minimum and maximum MAE metrics for each validation step\n",
    "* log the MAE metrics for each estimator of the multi-model for each validation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49da849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name='validate'):\n",
    "    n_fold = 10\n",
    "    n_estimators = 10\n",
    "    n_models = 10\n",
    "    # TODO: log parameters\n",
    "    model = None\n",
    "    maes, preds_train = None, None\n",
    "    # TODO: log preds_train.reset_index()\n",
    "    fig = None\n",
    "    # TODO: log fig with mlflow_log_plotly\n",
    "    # for i, mae in enumerate(maes):\n",
    "    #     mlflow.log_metric('MAE_MIN', mae.min(), step=i)\n",
    "    #     mlflow.log_metric('MAE_MAX', mae.max(), step=i)\n",
    "    #     for j, result in enumerate(mae):\n",
    "    #         mlflow.log_metric('MAE{}'.format(j), result, step=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52246f1",
   "metadata": {},
   "source": [
    "**Exercise:** visualize the range of possible MAEs in the graphical interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906bb152",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e871ae9",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "<a class='anchor' id='spart24'></a>\n",
    "\n",
    "Training the model on the entire training set.\n",
    "\n",
    "**Exercise:** create a run [MLflow](https://mlflow.org/) that:\n",
    "* is called `train`\n",
    "* log the parameters `start_week`, `end_week`, `n_estimators`, `n_models`.\n",
    "* train the multi-model on the training set `x_train / y_train`\n",
    "* log its `single_estimator` attribute, which is a standard scikit-learn model, to the `simple_model` directory\n",
    "* log the complete model, which is a custom model, in the `multi_model` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078e07f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f329dd7",
   "metadata": {},
   "source": [
    "## Online feature engineering\n",
    "\n",
    "<a class='anchor' id='spart25'></a>\n",
    "\n",
    "Feature engineering and building the prediction game.\n",
    "\n",
    "**Exercise:** create a run [MLflow](https://mlflow.org/) that:\n",
    "* is called `future`\n",
    "* logs the `next_week` parameter\n",
    "* loads and cleans up a recent past week `past` to calculate turnover lags, via the `etl` function\n",
    "* generates a prediction set `x_pred` via the `span_future` function\n",
    "* perform online feature engineering via the `features_online` function\n",
    "* log the obtained prediction set in `prediction_set/x_pred.csv` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81adddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name='future'):\n",
    "    # TODO: log parameters\n",
    "    past = etl(settings.DATA_DIR, next_week - 1, next_week - 1)\n",
    "    x_pred = span_future(past['order_date'].max())\n",
    "    x_pred = None\n",
    "    # TODO: log x_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4092f3",
   "metadata": {},
   "source": [
    "## Predicting\n",
    "\n",
    "<a class='anchor' id='spart26'></a>\n",
    "\n",
    "Predicting the model over the next week.\n",
    "\n",
    "**Exercise:** create a run [MLflow](https://mlflow.org/) that:\n",
    "* is called `predict`\n",
    "* log the parameters `next_week`, `start_week`, `end_week`, `n_estimators`, `n_models`\n",
    "* pass the date in index in `x_pred`\n",
    "* predict the turnover `y_pred` on `x_pred`\n",
    "* log the predictions in `predictions/y_pred.csv` (don't forget to `reset_index()`)\n",
    "* log the figure obtained via `plotly_predictions` in `plots/predictions.html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28d5a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name='predict'):\n",
    "    # TODO: log parameters\n",
    "    # x_pred = x_pred.set_index('order_date')\n",
    "    y_pred = None\n",
    "    # log y_pred.reset_index()\n",
    "    fig = None\n",
    "    # log fig with mlflow_log_plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6739bccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdb2b9e",
   "metadata": {},
   "source": [
    "# Congrats !\n",
    "\n",
    "You know master the [tracking](https://www.mlflow.org/docs/latest/tracking.html) [model flavours](https://www.mlflow.org/docs/latest/tracking.html) parts of MLflow !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73e00ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "foodcast",
   "language": "python",
   "name": "foodcast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
